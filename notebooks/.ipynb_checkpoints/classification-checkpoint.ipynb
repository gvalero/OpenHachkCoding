{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['axes', 'boots', 'carabiners', 'crampons', 'gloves', 'hardshell_jackets', 'harnesses', 'helmets', 'insulated_jackets', 'pulleys', 'rope', 'tents']\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir(data_dir)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration\n",
    "img_width, img_height = 128, 128\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for label in labels:\n",
    "    files = (os.listdir(os.path.join(data_dir,label)))\n",
    "    for file in files:\n",
    "        img = Image.open(os.path.join(data_dir, label,file)).convert('RGB')\n",
    "        width, height = img.size\n",
    "        if height> width:\n",
    "            ratio = float(img_height/height)\n",
    "        else:\n",
    "            ratio = float(img_width/width)\n",
    "        new_size = int(width*ratio), int(height*ratio)\n",
    "        img = img.resize(new_size, Image.ANTIALIAS)\n",
    "        delta_w = img_width - img.size[0]\n",
    "        delta_h = img_height - img.size[1]\n",
    "        padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "        img = ImageOps.expand(img, padding, fill='white')\n",
    "        data = np.asarray(img)\n",
    "        X.append(data)\n",
    "        y.append(labels.index(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "X, y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3277128, 1: 2603457, 2: 8583803, 3: 3841970, 4: 4092267, 5: 9818918, 6: 4174152, 7: 2374193, 8: 4531202, 9: 928519, 10: 5585056, 11: 3703631}\n"
     ]
    }
   ],
   "source": [
    "colors = {}\n",
    "for idx, x in enumerate(X):\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    dict_ = (dict(zip(unique, counts)))\n",
    "    if y[idx] not in colors.keys():\n",
    "        colors[y[idx]] = 0\n",
    "    if 255 in dict_.keys():\n",
    "        colors[y[idx]]+=(dict_[255])\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(labels))\n",
    "plt.bar(x, height= [1,2,3])\n",
    "plt.xticks(x+.5, ['a','b','c']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lahulsta\\appdata\\local\\continuum\\anaconda3\\envs\\openhack\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1697 samples, validate on 425 samples\n",
      "Epoch 1/10\n",
      "1697/1697 [==============================] - 14s 8ms/step - loss: 0.0055 - acc: 0.5651 - val_loss: 0.0023 - val_acc: 0.8235\n",
      "Epoch 2/10\n",
      "1697/1697 [==============================] - 14s 8ms/step - loss: 0.0023 - acc: 0.8079 - val_loss: 0.0020 - val_acc: 0.8612\n",
      "Epoch 3/10\n",
      "1697/1697 [==============================] - 14s 8ms/step - loss: 0.0016 - acc: 0.8674 - val_loss: 0.0013 - val_acc: 0.9059\n",
      "Epoch 4/10\n",
      "1697/1697 [==============================] - 15s 9ms/step - loss: 8.5463e-04 - acc: 0.9287 - val_loss: 0.0015 - val_acc: 0.9035\n",
      "Epoch 5/10\n",
      "1697/1697 [==============================] - 16s 10ms/step - loss: 6.9606e-04 - acc: 0.9381 - val_loss: 0.0015 - val_acc: 0.9224\n",
      "Epoch 6/10\n",
      "1697/1697 [==============================] - 16s 9ms/step - loss: 5.8550e-04 - acc: 0.9523 - val_loss: 0.0012 - val_acc: 0.9200\n",
      "Epoch 7/10\n",
      "1697/1697 [==============================] - 16s 10ms/step - loss: 4.9479e-04 - acc: 0.9635 - val_loss: 0.0011 - val_acc: 0.9318\n",
      "Epoch 8/10\n",
      "1697/1697 [==============================] - 17s 10ms/step - loss: 4.8552e-04 - acc: 0.9629 - val_loss: 0.0011 - val_acc: 0.9412\n",
      "Epoch 9/10\n",
      "1697/1697 [==============================] - 16s 9ms/step - loss: 3.4899e-04 - acc: 0.9705 - val_loss: 0.0013 - val_acc: 0.9294\n",
      "Epoch 10/10\n",
      "1697/1697 [==============================] - 16s 10ms/step - loss: 2.3550e-04 - acc: 0.9782 - val_loss: 0.0013 - val_acc: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22411d485c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import random\n",
    "\n",
    "# dimensions of our images.\n",
    "num_classes=len(labels)\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 3)\n",
    "input_shape = (img_width, img_height, 3)\n",
    "X\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(X_train)/255, np.array(y_train)/255, validation_split=0.2, nb_epoch=10, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lahulsta\\appdata\\local\\continuum\\anaconda3\\envs\\openhack\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\lahulsta\\appdata\\local\\continuum\\anaconda3\\envs\\openhack\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., epochs=25)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "425/425 [==============================] - 26s 61ms/step - loss: 1.3047 - acc: 0.6100 - val_loss: 1.1946 - val_acc: 0.8118\n",
      "Epoch 2/25\n",
      "425/425 [==============================] - 19s 46ms/step - loss: 0.9267 - acc: 0.7124 - val_loss: 1.0934 - val_acc: 0.8047\n",
      "Epoch 3/25\n",
      "425/425 [==============================] - 17s 39ms/step - loss: 0.8746 - acc: 0.7441 - val_loss: 1.2226 - val_acc: 0.8518\n",
      "Epoch 4/25\n",
      "425/425 [==============================] - 21s 49ms/step - loss: 0.7522 - acc: 0.7782 - val_loss: 1.1822 - val_acc: 0.8565\n",
      "Epoch 5/25\n",
      "425/425 [==============================] - 21s 49ms/step - loss: 0.7623 - acc: 0.7747 - val_loss: 0.9256 - val_acc: 0.8776\n",
      "Epoch 6/25\n",
      "425/425 [==============================] - 20s 47ms/step - loss: 0.7087 - acc: 0.8024 - val_loss: 1.0988 - val_acc: 0.8471\n",
      "Epoch 7/25\n",
      "425/425 [==============================] - 23s 54ms/step - loss: 0.8059 - acc: 0.7800 - val_loss: 1.0667 - val_acc: 0.8541\n",
      "Epoch 8/25\n",
      "425/425 [==============================] - 20s 46ms/step - loss: 0.7224 - acc: 0.8006 - val_loss: 0.9221 - val_acc: 0.8824\n",
      "Epoch 9/25\n",
      "425/425 [==============================] - 18s 42ms/step - loss: 0.7185 - acc: 0.7912 - val_loss: 0.9613 - val_acc: 0.8918\n",
      "Epoch 10/25\n",
      "425/425 [==============================] - 24s 57ms/step - loss: 0.7337 - acc: 0.8006 - val_loss: 1.2175 - val_acc: 0.8565\n",
      "Epoch 11/25\n",
      "425/425 [==============================] - 19s 44ms/step - loss: 0.7124 - acc: 0.8141 - val_loss: 0.9762 - val_acc: 0.8706\n",
      "Epoch 12/25\n",
      "425/425 [==============================] - 18s 43ms/step - loss: 0.6484 - acc: 0.8282 - val_loss: 0.9969 - val_acc: 0.8800\n",
      "Epoch 13/25\n",
      "425/425 [==============================] - 21s 50ms/step - loss: 0.7220 - acc: 0.8112 - val_loss: 1.2041 - val_acc: 0.8635\n",
      "Epoch 14/25\n",
      "425/425 [==============================] - 20s 47ms/step - loss: 0.6522 - acc: 0.8259 - val_loss: 1.3571 - val_acc: 0.8635\n",
      "Epoch 15/25\n",
      "425/425 [==============================] - 21s 49ms/step - loss: 0.7242 - acc: 0.8147 - val_loss: 1.3212 - val_acc: 0.8565\n",
      "Epoch 16/25\n",
      "425/425 [==============================] - 21s 49ms/step - loss: 0.6616 - acc: 0.8224 - val_loss: 1.0498 - val_acc: 0.8776\n",
      "Epoch 17/25\n",
      "425/425 [==============================] - 22s 51ms/step - loss: 0.6814 - acc: 0.8288 - val_loss: 0.9461 - val_acc: 0.8965\n",
      "Epoch 18/25\n",
      "425/425 [==============================] - 26s 60ms/step - loss: 0.7247 - acc: 0.8206 - val_loss: 1.0498 - val_acc: 0.8659\n",
      "Epoch 19/25\n",
      "425/425 [==============================] - 27s 64ms/step - loss: 0.7020 - acc: 0.8265 - val_loss: 0.9746 - val_acc: 0.8871\n",
      "Epoch 20/25\n",
      "425/425 [==============================] - 28s 67ms/step - loss: 0.7066 - acc: 0.8229 - val_loss: 1.3051 - val_acc: 0.8306\n",
      "Epoch 21/25\n",
      "425/425 [==============================] - 27s 65ms/step - loss: 0.6914 - acc: 0.8212 - val_loss: 0.9771 - val_acc: 0.8776\n",
      "Epoch 22/25\n",
      "425/425 [==============================] - 27s 64ms/step - loss: 0.6604 - acc: 0.8382 - val_loss: 1.0771 - val_acc: 0.8871\n",
      "Epoch 23/25\n",
      "425/425 [==============================] - 24s 56ms/step - loss: 0.6068 - acc: 0.8412 - val_loss: 1.0764 - val_acc: 0.8871\n",
      "Epoch 24/25\n",
      "425/425 [==============================] - 23s 54ms/step - loss: 0.6821 - acc: 0.8429 - val_loss: 1.1214 - val_acc: 0.8871\n",
      "Epoch 25/25\n",
      "425/425 [==============================] - 20s 47ms/step - loss: 0.6670 - acc: 0.8429 - val_loss: 0.9213 - val_acc: 0.9153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2250ead5550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "X_train_, X_val = X_train[0:int(len(X_train)*0.8)], X_train[int(len(X_train)*0.8):]\n",
    "y_train_, y_val = y_train[0:int(len(y_train)*0.8)], y_train[int(len(y_train)*0.8):]\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen_train.fit(X_train_)\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen_val.fit(X_val)\n",
    "\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(128, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen_train.flow(X_train_, y_train_, batch_size=batch_size), validation_data=datagen_val.flow(X_val, y_val, batch_size=batch_size),nb_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
